# File: face_training.py (The Final, Safe & Unbiased Version)
import cv2
import os
import numpy as np
import pickle
import random
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.utils import to_categorical
from keras.optimizers import Adam
import time

# --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ---
DATASET_PATH = 'dataset'
IMG_SIZE = 64
MIN_FACE_SIZE = 20
# ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å 1 ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏î‡πâ‡∏ß‡∏¢ OpenCV
AUGMENTATIONS_PER_IMAGE = 5

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Augmentation ‡∏î‡πâ‡∏ß‡∏¢ OpenCV (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢) ---
def augment_image(image):
    augmented_image = image.copy()
    
    # 1. ‡∏û‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô (‡∏™‡∏∏‡πà‡∏° 50%)
    if random.random() > 0.5:
        augmented_image = cv2.flip(augmented_image, 1)

    # 2. ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á (‡∏™‡∏∏‡πà‡∏°)
    brightness_value = int(random.uniform(-40, 40))
    augmented_image = np.clip(augmented_image.astype(int) + brightness_value, 0, 255).astype(np.uint8)

    # 3. ‡∏´‡∏°‡∏∏‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡∏™‡∏∏‡πà‡∏°)
    rows, cols, _ = augmented_image.shape
    angle = random.uniform(-15, 15)
    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)
    augmented_image = cv2.warpAffine(augmented_image, M, (cols, rows), borderMode=cv2.BORDER_REPLICATE)

    # 4. ‡πÄ‡∏û‡∏¥‡πà‡∏° Gaussian Blur ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡∏™‡∏∏‡πà‡∏° 50%)
    if random.random() > 0.5:
        augmented_image = cv2.GaussianBlur(augmented_image, (5, 5), 0)
        
    return augmented_image

# --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ---
print("="*50)
print("      ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI (Advanced)      ")
print("="*50)

print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1/5] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏û‡∏π‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Augmentation)...")
faces = []
labels = []

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
person_folders = [p for p in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, p))]

for person_name in person_folders:
    person_dir = os.path.join(DATASET_PATH, person_name)
    print(f"  -> ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: '{person_name}'")
    for filename in os.listdir(person_dir):
        img_path = os.path.join(person_dir, filename)
        image = cv2.imread(img_path)
        if image is None: continue

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        detected_faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(MIN_FACE_SIZE, MIN_FACE_SIZE))

        for (x, y, w, h) in detected_faces:
            face_roi = image[y:y+h, x:x+w]
            resized_face = cv2.resize(face_roi, (IMG_SIZE, IMG_SIZE))
            
            # --- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á ---
            faces.append(resized_face)
            labels.append(person_name)
            
            # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ Augmentation (OpenCV) ---
            for _ in range(AUGMENTATIONS_PER_IMAGE):
                augmented = augment_image(resized_face)
                faces.append(augmented)
                labels.append(person_name)
            
print(f"\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1/5] ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(faces)} ‡∏£‡∏π‡∏õ (‡∏£‡∏ß‡∏° Augment)")

# --- 2. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2/5] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preprocessing)...")
if len(faces) == 0: exit("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤!")
if len(set(labels)) < 2: exit("‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏Ñ‡∏ô")

faces = np.array(faces, dtype='float32') / 255.0
le = LabelEncoder()
labels_int = le.fit_transform(labels)
num_classes = len(le.classes_)
labels_onehot = to_categorical(labels_int, num_classes=num_classes)
(trainX, testX, trainY, testY) = train_test_split(faces, labels_onehot, test_size=0.20, stratify=labels_int, random_state=42)

# --- 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Class Weights ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏≠‡∏ô‡πÄ‡∏≠‡∏µ‡∏¢‡∏á ---
print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3/5] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Class Weights...")
class_weights = class_weight.compute_class_weight(
    'balanced',
    classes=np.unique(labels_int),
    y=labels_int
)
class_weights_dict = dict(enumerate(class_weights))
print(f"  -> Class Weights ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡πâ‡∏ß: {class_weights_dict}")

# --- 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ---
print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4/5] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏°‡πÑ‡∏û‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
model = Sequential([
    Conv2D(32, (3, 3), padding="same", activation="relu", input_shape=(IMG_SIZE, IMG_SIZE, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Conv2D(64, (3, 3), padding="same", activation="relu"),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),
    
    Conv2D(128, (3, 3), padding="same", activation="relu"),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    # ===== ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ =====
    Conv2D(256, (3, 3), padding="same", activation="relu"),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),
    # ==========================

    Flatten(),
    
    Dense(512, activation="relu"),
    Dropout(0.5),
    Dense(num_classes, activation="softmax")
])
EPOCHS = 15
BS = 64 
opt = Adam(learning_rate=1e-4)
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])

# --- 5. ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° Class Weights ---
print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5/5] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
start_time = time.time()
model.fit(trainX, trainY, batch_size=BS, validation_data=(testX, testY), 
          epochs=EPOCHS, class_weight=class_weights_dict, verbose=1)
end_time = time.time()
print(f"\n‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {end_time - start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

# --- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
(loss, acc) = model.evaluate(testX, testY, verbose=0)
print(f"\n‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•:\n  -> Accuracy: {acc * 100:.2f}%")
model.save("face_recognition_model.h5")
with open("label_encoder.pickle", "wb") as f:
    f.write(pickle.dumps(le))
print("\nüéâüéâüéâ ‡∏™‡∏£‡πâ‡∏≤‡∏á '‡∏™‡∏°‡∏≠‡∏á' AI ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏â‡∏•‡∏≤‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß! üéâüéâüéâ")