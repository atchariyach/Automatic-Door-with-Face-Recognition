# File: face_recognition_app.py (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô Blink Detection + Arduino Control)
import cv2
import dlib
import numpy as np
import pickle
from keras.models import load_model
from scipy.spatial import distance as dist
import time
import serial

# --- 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ---
SHAPE_PREDICTOR_PATH = "shape_predictor_68_face_landmarks.dat"
EYE_AR_THRESH = 0.25
EYE_AR_CONSEC_FRAMES = 3
BLINKS_NEEDED = 2
CONFIDENCE_THRESHOLD = 0.70
RECOGNITION_IMG_SIZE = 64
LIVENESS_IMG_SIZE = 32

# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö ARDUINO ---
ARDUINO_PORT = 'COM3' # <--- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Port ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
try:
    arduino = serial.Serial(port=ARDUINO_PORT, baudrate=9600, timeout=.1)
    print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Arduino UNO ‡∏ó‡∏µ‡πà {ARDUINO_PORT} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
except serial.SerialException:
    arduino = None
    print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Arduino UNO ‡∏ó‡∏µ‡πà {ARDUINO_PORT} ‡πÑ‡∏î‡πâ")

def send_command_to_arduino(command):
    if arduino:
        try:
            arduino.write(bytes(command + "\n", 'utf-8'))
            time.sleep(0.05)
        except serial.SerialException:
            pass

# --- 2. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ---
print("="*50)
print("      Advanced Face Recognition + Per-Person Liveness      ")
print("="*50)
print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1/3] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
try:
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor(SHAPE_PREDICTOR_PATH)
    recognition_model = load_model("face_recognition_model.h5")
    with open("label_encoder.pickle", 'rb') as f:
        le = pickle.load(f)
    # --- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Liveness ‡∏î‡πâ‡∏ß‡∏¢ ---
    liveness_model = load_model("liveness_model.h5")
    with open("liveness_label_encoder.pickle", 'rb') as f:
        liveness_le = pickle.load(f)
    print("  -> ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
except Exception as e:
    input(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ\n   -> Error: {e}\n\n‡∏Å‡∏î Enter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏°‡∏ô‡∏π")
    exit()

# --- 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ ---
def eye_aspect_ratio(eye):
    A = dist.euclidean(eye[1], eye[5])
    B = dist.euclidean(eye[2], eye[4])
    C = dist.euclidean(eye[0], eye[3])
    ear = (A + B) / (2.0 * C)
    return ear

(lStart, lEnd) = (42, 48)
(rStart, rEnd) = (36, 42)
face_statuses = {}
next_face_id = 0
AUTHORIZED_USERS = [name.upper() for name in le.classes_]

# --- 4. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á ---
print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2/3] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°...")
cap = cv2.VideoCapture(0)
time.sleep(2.0)
send_command_to_arduino("UNAUTHORIZED") # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏ü‡πÅ‡∏î‡∏á

print("\n[‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3/3] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô...")
print("   -> ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏≠‡∏á '‡∏Å‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤ 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô")
while True:
    ret, frame = cap.read()
    if not ret: break

    frame = cv2.flip(frame, 1)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    rects = detector(rgb_frame, 0)
    current_face_centers = [(r.center().x, r.center().y) for r in rects]
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
    disappeared_ids = []
    for face_id, status in face_statuses.items():
        if not any(dist.euclidean(center, status["pos"]) < 75 for center in current_face_centers):
            disappeared_ids.append(face_id)
    for face_id in disappeared_ids:
        del face_statuses[face_id]

    is_authorized_person_in_frame = False

    # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
    for rect in rects:
        (x, y, w, h) = (rect.left(), rect.top(), rect.width(), rect.height())
        center = (rect.center().x, rect.center().y)
        
        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        existing_id = next((face_id for face_id, status in face_statuses.items() if dist.euclidean(center, status["pos"]) < 75), None)
        
        if existing_id is not None:
            face_statuses[existing_id]["pos"] = center
            status = face_statuses[existing_id]
        else:
            status = {
                "pos": center, "closed_counter": 0, "blinks": 0,
                "liveness_verified": False, "recognition_done": False,
                "name": "Blink 2 times", "color": (0, 255, 255)
            }
            face_statuses[next_face_id] = status
            next_face_id += 1

        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô Liveness ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ï‡∏≤
        if not status["liveness_verified"]:
            shape = predictor(rgb_frame, rect)
            shape = np.array([(shape.part(i).x, shape.part(i).y) for i in range(68)])
            ear = (eye_aspect_ratio(shape[lStart:lEnd]) + eye_aspect_ratio(shape[rStart:rEnd])) / 2.0

            if ear < EYE_AR_THRESH:
                status["closed_counter"] += 1
            else:
                if status["closed_counter"] >= EYE_AR_CONSEC_FRAMES:
                    status["blinks"] += 1
                status["closed_counter"] = 0
            
            status["name"] = f"Blinks: {status['blinks']}/{BLINKS_NEEDED}"
            if status["blinks"] >= BLINKS_NEEDED:
                status["liveness_verified"] = True
                print(f"  -> ‚úÖ Blink Liveness Verified for a face.")
        
        # ‡∏ñ‡πâ‡∏≤ Liveness ‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏î‡∏à‡∏≥‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        if status["liveness_verified"] and not status["recognition_done"]:
            face_roi = frame[y:y+h, x:x+w]
            if face_roi.size == 0: continue

            # --- ‡∏î‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Spoof ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• ---
            liveness_face = cv2.resize(face_roi, (LIVENESS_IMG_SIZE, LIVENESS_IMG_SIZE)).astype("float") / 255.0
            liveness_face = np.expand_dims(liveness_face, axis=0)
            liveness_preds = liveness_model.predict(liveness_face, verbose=0)[0]
            liveness_label = liveness_le.classes_[np.argmax(liveness_preds)]
            
            if liveness_label == "real":
                # --- ‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡∏î‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡πà 2 ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ---
                recog_face = cv2.resize(face_roi, (RECOGNITION_IMG_SIZE, RECOGNITION_IMG_SIZE)).astype("float") / 255.0
                recog_face = np.expand_dims(recog_face, axis=0)
                preds = recognition_model.predict(recog_face, verbose=0)[0]
                
                if np.max(preds) > CONFIDENCE_THRESHOLD:
                    name = le.classes_[np.argmax(preds)].upper()
                    status["name"] = name
                    status["color"] = (255, 0, 0) # ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô
                else:
                    status["name"] = "UNKNOWN"
                    status["color"] = (0, 0, 255) # ‡∏™‡∏µ‡πÅ‡∏î‡∏á
            else:
                status["name"] = "SPOOF DETECTED"
                status["color"] = (0, 0, 255) # ‡∏™‡∏µ‡πÅ‡∏î‡∏á
            
            status["recognition_done"] = True
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if status.get("recognition_done", False) and status["name"] in AUTHORIZED_USERS:
            is_authorized_person_in_frame = True

        # ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ
        cv2.rectangle(frame, (x, y), (x + w, y + h), status["color"], 2)
        cv2.putText(frame, status["name"], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, status["color"], 2)

    # --- ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏´‡πâ Arduino ---
    if is_authorized_person_in_frame:
        send_command_to_arduino("AUTHORIZED")
    else:
        send_command_to_arduino("UNAUTHORIZED")

    # --- ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• ---
    new_width = 1280
    new_height = 720
    display_frame = cv2.resize(frame, (new_width, new_height))
    cv2.imshow("Ultimate Secure Face Recognition", display_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

print("\nüëã ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°...")
send_command_to_arduino("UNAUTHORIZED")
if arduino: arduino.close()
cap.release()
cv2.destroyAllWindows()